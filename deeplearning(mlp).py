# -*- coding: utf-8 -*-
"""deepLearning(MLP).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qheyR0A-VlroRIUGVggDqlRksRdTc6uc
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
import re
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import cross_val_score

# Specify the path to your Excel file
excel_file_path = '/content/drive/MyDrive/intellicruit/test3Dataset.xlsx'

# Read the Excel file into a DataFrame
df = pd.read_excel(excel_file_path)

# Set options to display all rows and columns
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)


df.head(4)

# Shuffle the DataFrame rows
df = df.sample(frac=1, random_state=42)

# Reset the index of the shuffled DataFrame
df = df.reset_index(drop=True)

nltk.download('stopwords')
stop_words = stopwords.words('english')

def remove_stopwords(content):
    con = re.sub('[^a-zA-Z]', ' ', content)
    con = con.lower()
    con = con.split()
    con = [word for word in con if not word in stopwords.words('english')]
    con = ' '.join(con)
    return con

df['Skill'] = df['Skill'].apply(remove_stopwords)

from sklearn.preprocessing import LabelEncoder
le_x= LabelEncoder()
df.Career = le_x.fit_transform(df.Career)

df.head(4)

unique_classes = le_x.classes_
for label, encoded_value in zip(unique_classes, range(len(unique_classes))):
    print(f"{label} is encoded as {encoded_value}")

import pandas as pd
import matplotlib.pyplot as plt

# Mapping encoded labels to their respective strings
labels = {
    0: 'Artificial Intelligence',
    1: 'Data Science',
    2: 'Development',
    3: 'Security',
    4: 'Software Development and Engineering',
    5: 'User Experience (UX) and User Interface (UI) Design'
}

# Count occurrences of each label
label_counts = df['Career'].value_counts()

# Calculate percentage for each label
percentages = (label_counts / len(df)) * 100

# Generate labels for the pie chart (with count and percentage)
labels_for_plot = [f"{labels[label]} - {label_counts[label]} ({percentages[label]:.1f}%)"
                   for label in label_counts.index]

# Plotting the pie chart
plt.figure(figsize=(8, 8))
plt.pie(label_counts, labels=labels_for_plot, autopct='', startangle=140)
plt.title('Percentage of Career Labels')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# Mapping encoded labels to their respective strings
labels = {
    0: 'Artificial Intelligence',
    1: 'Data Science',
    2: 'Development',
    3: 'Security',
    4: 'Software Development and Engineering',
    5: 'User Experience (UX) and User Interface (UI) Design'
}

# Define the percentages for train-test split
train_percentage = 0.8
test_percentage = 0.2

# Empty DataFrames to store train and test splits
train_data = pd.DataFrame()
test_data = pd.DataFrame()

# Iterate through each class
for label, total_count in labels.items():
    # Filter rows for the current label
    subset = df[df['Career'] == label]

    # Perform train-test split for the subset
    train_subset, test_subset = train_test_split(subset, train_size=train_percentage, test_size=test_percentage)

    # Append train and test splits to respective DataFrames
    train_data = train_data.append(train_subset)
    test_data = test_data.append(test_subset)

# Shuffle the DataFrame rows
train_data = train_data.sample(frac=1, random_state=42)

# Reset the index of the shuffled DataFrame
train_data = train_data.reset_index(drop=True)

# Shuffle the DataFrame rows
test_data = test_data.sample(frac=1, random_state=42)

# Reset the index of the shuffled DataFrame
test_data = test_data.reset_index(drop=True)

x_train = train_data['Skill']
x_test = test_data['Skill']

y_train = train_data['Career']
y_test = test_data['Career']

# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import LabelEncoder
# import tensorflow as tf
# from transformers import GPT2Tokenizer, TFGPT2Model
# from tensorflow.keras.models import Model
# from tensorflow.keras.layers import Input, Dense, Flatten, Dropout

# # Tokenize the text using GPT2Tokenizer
# tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
# tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add a new pad token
# tokenizer.pad_token = tokenizer.eos_token  # Set pad_token to eos_token

# # Tokenize training data
# x_train_gpt = tokenizer(list(x_train), truncation=True, padding=True, return_tensors="tf", max_length=52)  # Adjust max_length

# # Tokenize test data
# x_test_gpt = tokenizer(list(x_test), truncation=True, padding=True, return_tensors="tf", max_length=52)  # Adjust max_length

# # Ensure the sequence length matches the model's expected input shape
# sequence_length = x_train_gpt["input_ids"].shape[1]

# # Define batch size
# batch_size = 32

# # Load pre-trained GPT2 model
# gpt_model = TFGPT2Model.from_pretrained("gpt2")

# # Freeze GPT2 layers (optional, depending on the amount of data you have)
# for layer in gpt_model.layers:
#     layer.trainable = False

# # Use Keras Functional API to build the model
# inputs = Input(shape=(sequence_length,), dtype=tf.int32, name="input_ids")  # Adjust shape based on the actual sequence length
# gpt_output = gpt_model(inputs)["last_hidden_state"]
# flatten_layer = Flatten()(gpt_output)
# dropout_layer = Dropout(0.5)(flatten_layer)

# # Create the model
# model = Model(inputs=inputs, outputs=dropout_layer)

# # Compile the model
# model.compile(optimizer='adam',
#               loss='sparse_categorical_crossentropy',
#               metrics=['accuracy'])

# # Create TensorFlow datasets
# train_dataset = tf.data.Dataset.from_tensor_slices(({"input_ids": x_train_gpt["input_ids"]}, y_train))
# test_dataset = tf.data.Dataset.from_tensor_slices(({"input_ids": x_test_gpt["input_ids"]}, y_test))

# # Batch the datasets
# train_dataset = train_dataset.batch(batch_size)
# test_dataset = test_dataset.batch(batch_size)

# # Train the model using the TensorFlow datasets
# model.fit(train_dataset, epochs=3)

# # Evaluate the model on the test data
# accuracy = model.evaluate(test_dataset)
# print("Test Accuracy:", accuracy[1])

vect=TfidfVectorizer()
x_train=vect.fit_transform(x_train)
x_test=vect.transform(x_test)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout, GlobalMaxPooling1D, Reshape

# Split the training data into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

# Create TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((x_train.toarray(), y_train))
val_dataset = tf.data.Dataset.from_tensor_slices((x_val.toarray(), y_val))
test_dataset = tf.data.Dataset.from_tensor_slices((x_test.toarray(), y_test))

# Define batch size
batch_size = 5

# Shuffle and batch the datasets
train_dataset = train_dataset.shuffle(buffer_size=x_train.getnnz()).batch(batch_size)
val_dataset = val_dataset.batch(batch_size)
test_dataset = test_dataset.batch(batch_size)

print(test_dataset)

from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Sequential

# Define the MLP model with additional hidden layers and adjusted dropout rates
mlp_model = Sequential()
mlp_model.add(Dense(128, activation='relu', input_shape=(x_train.shape[1],)))
mlp_model.add(Dropout(0.5))  # Adding dropout for regularization
mlp_model.add(Dense(64, activation='relu'))
mlp_model.add(Dropout(0.5))

# Additional hidden layers with dropout
mlp_model.add(Dense(32, activation='relu'))
mlp_model.add(Dropout(0.4))
mlp_model.add(Dense(16, activation='relu'))
mlp_model.add(Dropout(0.3))

# Output layer, number of units equal to the number of classes
num_classes = len(np.unique(y_train))
mlp_model.add(Dense(num_classes, activation='softmax'))

# Compile the model
mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
mlp_model.fit(train_dataset, epochs=50, validation_data=val_dataset)

# Evaluate the model on the test set
test_loss, test_accuracy = mlp_model.evaluate(test_dataset)
print(f'MLP Model Test Accuracy: {test_accuracy}')

import matplotlib.pyplot as plt

# Train the model and store the training history
history = mlp_model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=0)

# Extract the training and validation loss from the history
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Create a range of epochs
epochs = range(1, len(train_loss) + 1)

# Plot the learning curves
plt.plot(epochs, train_loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions
predictions = mlp_model.predict(test_dataset)
predicted_labels = np.argmax(predictions, axis=1)

# Generate confusion matrix
cm = confusion_matrix(y_test, predicted_labels)
print(cm)
# Display the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Generate classification report
report = classification_report(y_test, predicted_labels)
print("Classification Report:\n", report)

precision_mlp, recall_mlp, f1_mlp, support_mlp = precision_recall_fscore_support(y_test, predicted_labels, average=None)

# Compute weighted average
weighted_precision_mlp = np.sum(precision_mlp * support_mlp) / np.sum(support_mlp)
weighted_recall_mlp = np.sum(recall_mlp * support_mlp) / np.sum(support_mlp)
weighted_f1_mlp = np.sum(f1_mlp * support_mlp) / np.sum(support_mlp)

print(f"Weighted Precision for MLP: {weighted_precision_mlp}")
print(f"Weighted Recall for MLP: {weighted_recall_mlp}")
print(f"Weighted F1-Score for MLP: {weighted_f1_mlp}")